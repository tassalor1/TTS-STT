{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3062a6e5-bf21-48db-a631-daf013a1b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780a3d2-feee-412a-b390-298a268572b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## take audio and transcribe audio to text file\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Load audio\n",
    "audio_folder = \"D:/coding/ai_assistant/training_data\"\n",
    "audio_files = [f for f in os.listdir(audio_folder) if f.endswith(\".mp3\")]\n",
    "transcription_folder = \"D:/coding/ai_assistant/transcriptions\" \n",
    "\n",
    "for audio_file in audio_files:\n",
    "    audio_path = os.path.join(audio_folder, audio_file)\n",
    "    audio_path = audio_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "    #convert mp3 to wav for sr libary\n",
    "    audio = AudioSegment.from_mp3(audio_path)\n",
    "    wav_path = audio_path.replace(\".mp3\", \".wav\")\n",
    "    audio.export(wav_path, format=\"wav\")\n",
    "    \n",
    "    # transcribe audio to text\n",
    "    with sr.AudioFile(wav_path) as source:\n",
    "        audio = recognizer.record(source)  # record the  audio file\n",
    "        transcription = recognizer.recognize_sphinx(audio)  \n",
    "    \n",
    "    # save the transcription to a text file\n",
    "    transcription_file_name = f\"transcription_{audio_file}.txt\"\n",
    "    transcription_file_path = os.path.join(transcription_folder, transcription_file_name)\n",
    "\n",
    "    with open(transcription_file_path, \"w\") as file:\n",
    "        file.write(transcription)\n",
    "\n",
    "    print(f\"Transcription {audio_file} saved to {transcription_file_path}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bb94b95-8f4f-4a4a-a691-b2b7026aca59",
   "metadata": {},
   "source": [
    "run docker container of the gentle alignment libary\n",
    "\n",
    "docker pull lowerquality/gentle\n",
    "\n",
    "docker run -P lowerquality/gentle\n",
    "\n",
    "#check which port\n",
    "docker ps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958643ac-0e37-4227-bc23-976acaf85316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment data saved to D:/coding/ai_assistant/audio_alignment\\alignment_twentyyearsonhorseback_00_weekley_64kb.json\n",
      "Alignment data saved to D:/coding/ai_assistant/audio_alignment\\alignment_twentyyearsonhorseback_01_weekley_64kb.json\n",
      "Alignment data saved to D:/coding/ai_assistant/audio_alignment\\alignment_twentyyearsonhorseback_02_weekley_64kb.json\n",
      "Alignment data saved to D:/coding/ai_assistant/audio_alignment\\alignment_twentyyearsonhorseback_03_weekley_64kb.json\n",
      "Alignment data saved to D:/coding/ai_assistant/audio_alignment\\alignment_twentyyearsonhorseback_04_weekley_64kb.json\n",
      "Alignment data saved to D:/coding/ai_assistant/audio_alignment\\alignment_twentyyearsonhorseback_05_weekley_64kb.json\n",
      "Alignment data saved to D:/coding/ai_assistant/audio_alignment\\alignment_twentyyearsonhorseback_06_weekley_64kb.json\n",
      "Alignment data saved to D:/coding/ai_assistant/audio_alignment\\alignment_twentyyearsonhorseback_07_weekley_64kb.json\n",
      "Alignment data saved to D:/coding/ai_assistant/audio_alignment\\alignment_twentyyearsonhorseback_08_weekley_64kb.json\n"
     ]
    }
   ],
   "source": [
    "url = 'http://localhost:32768/transcriptions?async=false'\n",
    "audio_folder = \"D:/coding/ai_assistant/audio_data\"\n",
    "transcript_folder = \"D:/coding/ai_assistant/transcriptions\"\n",
    "output_folder = \"D:/coding/ai_assistant/audio_alignment\"\n",
    "\n",
    "audio_files = [f for f in os.listdir(audio_folder) if f.endswith(\".wav\")]\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    # get the transcript filename from the audio filename\n",
    "    transcript_file = \"transcription_\" + audio_file.replace(\".wav\", \".mp3\") + \".txt\"\n",
    "    \n",
    "    # full paths to the audio and transcript files\n",
    "    audio_path = os.path.join(audio_folder, audio_file)\n",
    "    transcript_path = os.path.join(transcript_folder, transcript_file)\n",
    " \n",
    "    if os.path.exists(transcript_path):\n",
    "        # request to Gentle api\n",
    "        with open(audio_path, 'rb') as audio, open(transcript_path, 'r') as transcript:\n",
    "            response = requests.post(url, files={'audio': audio, 'transcript': transcript})\n",
    "     \n",
    "        if response.status_code == 200:\n",
    "            alignment_data = response.json()\n",
    "            \n",
    "            # output file path\n",
    "            output_file = f\"alignment_{audio_file.replace('.wav', '.json')}\"\n",
    "            output_path = os.path.join(output_folder, output_file)\n",
    "        \n",
    "    \n",
    "            with open(output_path, 'w') as outfile:\n",
    "                json.dump(alignment_data, outfile, indent=4)\n",
    "            \n",
    "            print(f\"Alignment data saved to {output_path}\")\n",
    "        else:\n",
    "            print(f'Failed to process alignment: {response.status_code}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75c20246-fe53-4d18-bd1a-f3358a737235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata.csv file has been created at D:/coding/ai_assistant/dataset/metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "txt_folder = \"D:/coding/ai_assistant/dataset/transcriptions\"\n",
    "wavs_folder = \"D:/coding/ai_assistant/dataset/wav\"\n",
    "output_csv_file = \"D:/coding/ai_assistant/dataset/metadata.csv\"  # Fixed the path\n",
    "\n",
    "def get_transcription(txt_file_path):\n",
    "    with open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "# Create metadata.csv file\n",
    "with open(output_csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['wav_file', 'transcription']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter='|')\n",
    "\n",
    "    # Loop through each wav file in the wavs folder\n",
    "    for wav_file_name in os.listdir(wavs_folder):\n",
    "        wav_file_path = os.path.join(wavs_folder, wav_file_name)\n",
    "        txt_file_name = \"transcription_\" + wav_file_name.replace(\".wav\", \".txt\")  # Fixed the extension to .txt\n",
    "        txt_file_path = os.path.join(txt_folder, txt_file_name)\n",
    "\n",
    "        # Check if the corresponding txt file exists\n",
    "        if os.path.exists(txt_file_path):\n",
    "            transcription = get_transcription(txt_file_path)\n",
    "            writer.writerow({'wav_file': wav_file_path, 'transcription': transcription})  # Use wav_file_path to include the full path\n",
    "        else:\n",
    "            print(f\"No matching txt file found for {wav_file_name}\")\n",
    "\n",
    "print(f'csv file has been created at {output_csv_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "022f1bcc-b532-48c8-bd73-1a92215874c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"D:/coding/ai_assistant/dataset/metadata.csv\"\n",
    "data = pd.read_csv(csv_path, delimiter='|', header=None, names=['wav_file', 'transcription'])\n",
    "\n",
    "#split data\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_csv= \"dataset/train_csv_file.csv\"\n",
    "val_csv = \"dataset/val_csv_file.csv\"\n",
    "\n",
    "train_data.to_csv(train_csv, sep='|', index=False, header=False)\n",
    "val_data.to_csv(val_csv, sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a149eaf7-a2ea-4fb1-8d2f-3a2ec654771b",
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['python', 'TTS/TTS/bin/train_tts.py', '--config_path', 'D:/coding/ai_assistant/TTS/TTS/config.json']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 47\u001b[0m\n\u001b[0;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_description\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts_model_training\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     },\n\u001b[0;32m     42\u001b[0m }\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# with open('config.json', 'w') as config_file:\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#     json.dump(config, config_file, indent=4)\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTTS/TTS/bin/train_tts.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--config_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:/coding/ai_assistant/TTS/TTS/config.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[1;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['python', 'TTS/TTS/bin/train_tts.py', '--config_path', 'D:/coding/ai_assistant/TTS/TTS/config.json']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"run_name\": \"run1\",\n",
    "    \"run_description\": \"tts_model_training\",\n",
    "    \"model\": \"Tacotron2\", \n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 32,\n",
    "    \"audio\": {\n",
    "        \"num_mels\": 80,\n",
    "        \"num_freq\": 1025,\n",
    "        \"sample_rate\": 22050,\n",
    "        \"frame_length_ms\": 50,\n",
    "        \"frame_shift_ms\": 12.5,\n",
    "        \"preemphasis\": 0.97,\n",
    "        \"min_level_db\": -100,\n",
    "        \"ref_level_db\": 20,\n",
    "        \"power\": 1.5,\n",
    "        \"griffin_lim_iters\": 60,\n",
    "        \"signal_norm\": True,\n",
    "        \"symmetric_norm\": True,\n",
    "        \"max_norm\": 4.0,\n",
    "        \"clip_norm\": True,\n",
    "        \"mel_fmin\": 0.0,\n",
    "        \"mel_fmax\": 8000.0\n",
    "    },   \n",
    "    \"datasets\": [\n",
    "        {\n",
    "            \"name\": \"audio_test\",\n",
    "            \"path\": \"D:/coding/ai_assistant/dataset\",\n",
    "            \"meta_file_train\": \"train.csv\",\n",
    "            \"meta_file_val\": \"val.csv\"\n",
    "        }\n",
    "    ],\n",
    "    \"optimizer\": \"RAdam\",\n",
    "    \"optimizer_params\": {\n",
    "        \"betas\": [0.9, 0.998],\n",
    "        \"eps\": 1e-6\n",
    "    },\n",
    "    \"lr_scheduler\": \"ExponentialScheduler\",\n",
    "    \"lr_scheduler_params\": {\n",
    "        \"gamma\": 0.99,\n",
    "    },\n",
    "}\n",
    "\n",
    "with open('config.json', 'w') as config_file:\n",
    "    json.dump(config, config_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39b67bb2-41d7-40e4-b6d7-e991554ca637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return code: 1\n",
      "--- STDOUT ---\n",
      "\n",
      "--- STDERR ---\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\coding\\ai_assistant\\TTS\\TTS\\bin\\train_tts.py\", line 4, in <module>\n",
      "    from trainer import Trainer, TrainerArgs\n",
      "ModuleNotFoundError: No module named 'trainer'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run(\n",
    "    ['python', 'TTS/TTS/bin/train_tts.py', '--config_path', 'D:/coding/ai_assistant/TTS/TTS/config.json'],\n",
    "    text=True,\n",
    "    capture_output=True\n",
    ")\n",
    "\n",
    "print('Return code:', result.returncode)\n",
    "print('--- STDOUT ---')\n",
    "print(result.stdout)\n",
    "print('--- STDERR ---')\n",
    "print(result.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-venv",
   "language": "python",
   "name": "ai-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
